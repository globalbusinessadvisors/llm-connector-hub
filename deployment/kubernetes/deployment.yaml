apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-connector-hub
  namespace: llm-connector-hub
  labels:
    app: llm-connector-hub
    version: v1
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: llm-connector-hub
  template:
    metadata:
      labels:
        app: llm-connector-hub
        version: v1
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      # Security context
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        fsGroup: 1001
        seccompProfile:
          type: RuntimeDefault

      # Service account
      serviceAccountName: llm-connector-hub

      # Init containers
      initContainers:
        - name: wait-for-redis
          image: busybox:1.35
          command:
            - 'sh'
            - '-c'
            - |
              until nc -z llm-redis 6379; do
                echo "Waiting for Redis..."
                sleep 2
              done
              echo "Redis is ready!"

      # Main containers
      containers:
        - name: llm-connector-hub
          image: llm-connector-hub:latest
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: metrics
              containerPort: 9090
              protocol: TCP

          # Environment variables from ConfigMap
          envFrom:
            - configMapRef:
                name: llm-connector-hub-config
            - secretRef:
                name: llm-connector-hub-secrets

          # Resource limits and requests
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"

          # Liveness probe
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
            successThreshold: 1

          # Readiness probe
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
            successThreshold: 1

          # Startup probe
          startupProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 0
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 30
            successThreshold: 1

          # Security context for container
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1001
            capabilities:
              drop:
                - ALL

          # Volume mounts
          volumeMounts:
            - name: tmp
              mountPath: /tmp
            - name: logs
              mountPath: /app/logs
            - name: cache
              mountPath: /app/cache

      # Volumes
      volumes:
        - name: tmp
          emptyDir: {}
        - name: logs
          emptyDir: {}
        - name: cache
          emptyDir:
            sizeLimit: 1Gi

      # Node affinity and tolerations
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - llm-connector-hub
                topologyKey: kubernetes.io/hostname

      # Termination grace period
      terminationGracePeriodSeconds: 30

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-redis
  namespace: llm-connector-hub
  labels:
    app: llm-redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-redis
  template:
    metadata:
      labels:
        app: llm-redis
    spec:
      containers:
        - name: redis
          image: redis:7-alpine
          ports:
            - name: redis
              containerPort: 6379
              protocol: TCP
          command:
            - redis-server
            - --appendonly
            - "yes"
            - --maxmemory
            - "512mb"
            - --maxmemory-policy
            - "allkeys-lru"
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "250m"
          livenessProbe:
            exec:
              command:
                - redis-cli
                - ping
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            exec:
              command:
                - redis-cli
                - ping
            initialDelaySeconds: 5
            periodSeconds: 5
          volumeMounts:
            - name: redis-data
              mountPath: /data
      volumes:
        - name: redis-data
          persistentVolumeClaim:
            claimName: llm-redis-pvc

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: llm-redis-pvc
  namespace: llm-connector-hub
  labels:
    app: llm-redis
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard
