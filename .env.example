# LLM Connector Hub - Environment Variables
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control!

# ================================
# Application Configuration
# ================================
NODE_ENV=development
PORT=8080
LOG_LEVEL=debug
LOG_FORMAT=pretty

# ================================
# Provider API Keys
# ================================

# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_ORGANIZATION=

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-...

# Google (Vertex AI / Gemini)
GOOGLE_API_KEY=
GOOGLE_APPLICATION_CREDENTIALS=

# AWS Bedrock
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1

# Azure OpenAI
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_DEPLOYMENT=

# ================================
# Redis Configuration
# ================================
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=
REDIS_MAX_RETRIES=3
REDIS_RETRY_DELAY=1000

# ================================
# Cache Configuration
# ================================
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# ================================
# Rate Limiting
# ================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100

# ================================
# Timeout Configuration
# ================================
REQUEST_TIMEOUT_MS=30000
PROVIDER_TIMEOUT_MS=60000

# ================================
# Retry Configuration
# ================================
MAX_RETRIES=3
RETRY_DELAY_MS=1000
RETRY_BACKOFF_MULTIPLIER=2

# ================================
# Security
# ================================
JWT_SECRET=your-jwt-secret-here
ENCRYPTION_KEY=your-encryption-key-here
CORS_ORIGIN=*
CORS_CREDENTIALS=true

# ================================
# Observability
# ================================

# Metrics
METRICS_ENABLED=true
METRICS_PORT=9090

# Tracing
ENABLE_TRACING=false
JAEGER_ENDPOINT=http://localhost:14268/api/traces

# Health Checks
HEALTH_CHECK_INTERVAL_MS=30000

# ================================
# Feature Flags
# ================================
ENABLE_STREAMING=true
ENABLE_FUNCTION_CALLING=true
ENABLE_VISION=true

# ================================
# Docker Registry (for deployment)
# ================================
DOCKER_REGISTRY=
IMAGE_TAG=latest

# ================================
# Kubernetes Configuration
# ================================
K8S_NAMESPACE=llm-connector-hub
K8S_CLUSTER_NAME=

# ================================
# Database (if needed)
# ================================
DATABASE_URL=postgresql://user:password@localhost:5432/llmhub
DATABASE_POOL_MIN=2
DATABASE_POOL_MAX=10

# ================================
# Development
# ================================
DEBUG=llm-connector:*
NODE_OPTIONS=--max-old-space-size=4096
